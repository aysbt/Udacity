{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differantial Private Deep Learning\n",
    "\n",
    "When our neural network are learning from sensitive data, that thay are only learning what they're supposed to learn from the data without accidentally learning they are not supposed to learn from the data.\n",
    "\n",
    "The general goal of differantial privacy is to ensure that different kind of statistical analysis do not compromise the privacy.\n",
    "\n",
    "The defination of Privacy: You will not affected, adversly on otherwise, by allowing your data to be used in any study on analysis, no matter what other studies,datasets, orinformation sources, are avaible.\n",
    "\n",
    "\n",
    "Exercise\n",
    "* Step one is to create our database - we're going to do this by initializing a random list of 1s and 0s (which are the entries in our database). Note - the number of entries directly corresponds to the number of people in our database.\n",
    "\n",
    "*  I want you to create a list of every parallel database to the one currently contained in the \"db\" variable. Then, I want you to create a function which both:\n",
    "\n",
    "    * creates the initial database (db)\n",
    "    * creates all parallel databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to crete a databse\n",
    "import torch\n",
    "def remove_index(db,index):\n",
    "    \"\"\"Remove the defined index from database\"\"\"\n",
    "    #removing the index\n",
    "    return torch.cat((db[0:index],db[index + 1:]))\n",
    "\n",
    "def paralle_db(db):\n",
    "    \"\"\"Create paralel data base for a given database with using remove_index function\"\"\"\n",
    "    #create the empty list for paralel databases\n",
    "    paralel_dbs = list()\n",
    "    #loop over the database\n",
    "    for i in range(len(db)):\n",
    "        #create the database for each removed index\n",
    "        dbs = remove_index(db,i)\n",
    "        #appande the removed databases to list of paralel databases\n",
    "        paralel_dbs.append(dbs)\n",
    "    return paralel_dbs\n",
    "\n",
    "def create_and_paralel(num_enrty):\n",
    "    \"\"\"Create simple database for a single column and then call the parael_db to\n",
    "    create paralal databases for each removed index value\"\"\"\n",
    "    #create the simple database for specific number \n",
    "    db = torch.rand(num_enrty) > 0.5\n",
    "    #call paralle_bd function to create paralal databases for spefic number of element\n",
    "    pbds = paralle_db(db)\n",
    "    return db, pbds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd, pdbs = create_and_paralel(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 0, 1,  ..., 0, 0, 0], dtype=torch.uint8), tensor([1, 0, 1,  ..., 0, 0, 0], dtype=torch.uint8), tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.uint8), tensor([1, 1, 0,  ..., 0, 0, 0], dtype=torch.uint8), tensor([1, 1, 0,  ..., 0, 0, 0], dtype=torch.uint8)]\n"
     ]
    }
   ],
   "source": [
    "#let's check out first 6 tenser list from pdbs\n",
    "print(pdbs[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the The Privacy of the Function\n",
    "\n",
    "*  How to query this database\n",
    "* then measure the privacy of that query\n",
    "\n",
    "We are going to compare the output of the query on the entire database, with the output of the query on each of the paralel databases. That way, we are going to how the query change, when we remove an individual from tha database.\n",
    "\n",
    "* We are going to query the full database\n",
    "* Weare going to look at quering every possible paralel database\n",
    "* What's the maxmimum around that they different?\n",
    "\n",
    "When we remove the people from this database, it changes the output of query. the output of this queryis actually conditionied directy on information from a lot of people in this databse.\n",
    "\n",
    "Sensitivity: The maximum amount that the query changes when removing an individual from the database. it is called L1 sensitivity for simply.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_and_paralel(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_db_result = query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivy = 0\n",
    "for dbs in pdbs:\n",
    "    pdb_result = query(dbs)\n",
    "    db_distance = torch.abs(pdb_result - full_db_result)\n",
    "    \n",
    "    if (db_distance > sensitivy):\n",
    "        sensitivy = db_distance\n",
    "    \n",
    "sensitivy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.float().mean()\n",
    "\n",
    "def sensitivity(query, n_entries =1000):\n",
    "    db, pdbs = create_and_paralel(n_entries)\n",
    "   \n",
    "    full_db_result = query(db)\n",
    "    sensitivity = 0\n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "\n",
    "        if(db_distance > sensitivity):\n",
    "            sensitivity = db_distance\n",
    "    \n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local & Global Differantial Privacy\n",
    "**Local differantial privacy:** Add noise to the function dat points\n",
    "**Global Differantial pricacy:** Add noise on the output query on the database\n",
    "\n",
    "## Local Differantial Privacy\n",
    "\n",
    "Where given a collection of individual, each individial adds noise to the their data before sending it to the statistical database itself. So, everything that gets through is alrready noised. So, the protection is happening at the local level. \n",
    "\n",
    "Differantial privacy always requires a form of randomness or noise added to the quey to protec from like differnatial attack.\n",
    "\n",
    "**Ransomized Responce:** Techniquie that is used social sciences when tring to a learn about the high level trends for a taban behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
